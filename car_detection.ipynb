{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "t3IZRlq_8HAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "FchlspdC6X6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade Pillow\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n"
      ],
      "metadata": {
        "id": "EVJ7pv_42uOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test_image_left.zip\""
      ],
      "metadata": {
        "id": "QhdVyf3dMLgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/train_iamge_left.zip\""
      ],
      "metadata": {
        "id": "AboouyhgMMqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "Lx-7CbMa8d5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5"
      ],
      "metadata": {
        "id": "ITCMSnWj3BA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpOEGhk-8wAg",
        "outputId": "b9c0ef89-33fc-40f4-fa17-5739a83ee0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 29.2/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/CSC420_car_detection/image_left/um_000004.jpg')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "vFcRY9mtKTiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yolov5\n"
      ],
      "metadata": {
        "id": "raus5J4S5CJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolov5 import YOLOv5\n",
        "\n",
        "model_path = \"yolov5s.pt\"\n",
        "yolov5_model = YOLOv5(model_path)\n"
      ],
      "metadata": {
        "id": "Zl05glFR5EGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "image_path = '/content/drive/MyDrive/CSC420_car_detection/image_left/um_000004.jpg'\n",
        "yolov5_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "yolov5_image = np.array(yolov5_image)\n"
      ],
      "metadata": {
        "id": "thphozMl5IQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolov5_results = yolov5_model.predict(yolov5_image, size=640)\n"
      ],
      "metadata": {
        "id": "XdhACciI5KXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_class_id = 2\n",
        "\n",
        "# Filter results for cars\n",
        "yolov5_car_detections = yolov5_results.xyxy[0][yolov5_results.xyxy[0][:, 5] == car_class_id]\n"
      ],
      "metadata": {
        "id": "UeJ4mkk95PRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Display the image with detections\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(yolov5_image)\n",
        "ax = plt.gca()\n",
        "\n",
        "for *xyxy, conf, cls in yolov5_car_detections:\n",
        "    x1, y1, x2, y2 = map(int, xyxy)\n",
        "    label = f'Car {conf:.2f}'\n",
        "    rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, color='red', linewidth=2)\n",
        "    ax.add_patch(rect)\n",
        "    # change the label position: vertical and horizontal alignment\n",
        "    ax.text(x1, y1-10, label, color='white', fontsize=8,\n",
        "            verticalalignment='top', horizontalalignment='left',\n",
        "            bbox=dict(facecolor='red', alpha=0.5, edgecolor='none', boxstyle='round,pad=0.1'))\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q3IuttSm5RTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on an Image\n"
      ],
      "metadata": {
        "id": "sOCOPAeyKwd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single image inference\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source '/content/drive/MyDrive/CSC420_car_detection/image_left/um_000004.jpg'"
      ],
      "metadata": {
        "id": "ssHQPZWpKWTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display.Image(filename='/content/yolov5/runs/detect/exp/um_000004.jpg', width=600)"
      ],
      "metadata": {
        "id": "zTqQdI44Kh-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on a Video"
      ],
      "metadata": {
        "id": "65hXgNfEKp2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# video inference\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source '/content/drive/MyDrive/CSC420_car_detection/test_image_left.mp4'"
      ],
      "metadata": {
        "id": "ynE_QSEzKZLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "video_path = '/content/yolov5/runs/detect/exp/output.mp4'\n",
        "\n",
        "# Compress and display the video inline\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=800 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n"
      ],
      "metadata": {
        "id": "dlzQCbJ_KeVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "\n",
        "model = YOLO('run/detect/train/weights/best.pt')\n",
        "\n",
        "results = model('test_images/000018.png', save=True)\n",
        "# results = model('test_videos/video_1.mp4', save=True)"
      ],
      "metadata": {
        "id": "jxcyF5j9_Pgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO v8\n"
      ],
      "metadata": {
        "id": "K4ovVpvG1xn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "SyoO-CW-10pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolov8_MODEL_PATH = \"yolov8x.pt\"  # Ensure the model file is in the working directory or provide the full path\n",
        "yolov8_model = YOLO(yolov8_MODEL_PATH)\n",
        "yolov8_model.fuse()  # Optional: Fusing the model can optimize its performance\n"
      ],
      "metadata": {
        "id": "lKLePdZg13bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolov8_image_path = '/content/drive/MyDrive/CSC420_car_detection/image_left/um_000004.jpg'\n",
        "yolov8_image = cv2.imread(yolov8_image_path, cv2.IMREAD_COLOR)\n",
        "yolov8_image = np.array(yolov8_image)\n",
        "\n",
        "# Perform detection\n",
        "yolov8_results = yolov8_model(yolov8_image)\n"
      ],
      "metadata": {
        "id": "wDrZhaaU14pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_class_id = 2  # Change this based on the specific class ID for cars in your model\n",
        "\n",
        "# Extract car detections\n",
        "yolov8_car_detections = yolov8_results[0].boxes[yolov8_results[0].boxes.cls == car_class_id]\n"
      ],
      "metadata": {
        "id": "rmS5o3pB16HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert detections to format suitable for display\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "boxes = yolov8_car_detections.xyxy.cpu().numpy()\n",
        "confidences = yolov8_car_detections.conf.cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(yolov8_image)\n",
        "ax = plt.gca()\n",
        "\n",
        "for box, confidence in zip(boxes, confidences):\n",
        "    x1, y1, x2, y2 = box.astype(int)\n",
        "    rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2)\n",
        "    ax.add_patch(rect)\n",
        "    # Label positioned above the bounding box and background made semi-transparent\n",
        "    label = f'Car {confidence:.2f}'\n",
        "    ax.text(x1, y1-10, label, color='white', fontsize=8,\n",
        "            verticalalignment='top', horizontalalignment='left',\n",
        "            bbox=dict(facecolor='red', alpha=0.5, edgecolor='none', boxstyle='round,pad=0.1'))\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MKhLaGfL17fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/CSC420_car_detection/test_image_left-ezgif.com-video-speed.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "\n",
        "# Check if the video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Define the codec and create VideoWriter object to save the output\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'mp4v' for .mp4 output\n",
        "out = cv2.VideoWriter('yolov5_test_image_left_output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "# Process the video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # End of video\n",
        "\n",
        "    # Convert frame to RGB from BGR (cv2 default)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform detection\n",
        "    results = model(frame_rgb)\n",
        "    car_detections = results.xyxy[0]  # First tensor [xyxy, conf, cls]\n",
        "\n",
        "    # Iterate through detections and draw boxes\n",
        "    for *xyxy, conf, cls in car_detections:\n",
        "        if cls == 2:  # Class '2' for cars\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f'Car: {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    # Save the frame with detections to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release everything when done\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Dgc-xlkY-DxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Car Detection + Viewpoint Classification (q8)"
      ],
      "metadata": {
        "id": "5PC6-CeYM-WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/saved_models-20240419T063014Z-001.zip\""
      ],
      "metadata": {
        "id": "RRXHfreuTmyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "\n",
        "# Define the folder containing the images\n",
        "folder_path = '/content/image_left'\n",
        "output_folder_path = '/content/yolov8_viewpoint'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "# Load the car detection YOLOv8 model\n",
        "yolov8_model_path = \"yolov8x.pt\"\n",
        "yolov8_model = YOLO(yolov8_model_path)\n",
        "\n",
        "# Load the viewpoint classification model\n",
        "viewpoint_model_path = '/content/saved_models/ResNet50_model_exp2.h5'\n",
        "viewpoint_model = load_model(viewpoint_model_path)\n",
        "\n",
        "# Class to angle mapping for viewpoint classification\n",
        "class_to_angle = {\n",
        "    0: 0, 1: 120, 2: 150, 3: 180, 4: 210, 5: 240,\n",
        "    6: 270, 7: 300, 8: 30, 9: 330, 10: 60, 11: 90\n",
        "}\n",
        "\n",
        "# Function to plot an arrow for viewpoint\n",
        "def plot_arrow(angle, car_box, ax):\n",
        "    radians = math.radians(angle-90)  # Adjust arrow direction\n",
        "    arrow_start = (car_box[0] + car_box[2]) // 2, car_box[3]  # Arrow starts at the bottom center of the car box\n",
        "    arrow_length = (car_box[2] - car_box[0]) // 2  # Arrow length is half the car box width\n",
        "    x_offset = arrow_length * math.cos(radians)\n",
        "    y_offset = arrow_length * math.sin(radians)\n",
        "    ax.annotate('', xy=arrow_start, xytext=(arrow_start[0] + x_offset, arrow_start[1] + y_offset),\n",
        "                arrowprops=dict(facecolor='red', shrink=0.05, width=1, headwidth=8),\n",
        "                horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "# # Read the test image\n",
        "# test_image_path = '/content/image_left/um_000004.jpg'  # Update this path\n",
        "# test_image = cv2.imread(test_image_path)\n",
        "# test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# # Perform car detection\n",
        "# yolov8_results = yolov8_model(test_image)\n",
        "# car_detections = yolov8_results[0].boxes[yolov8_results[0].boxes.cls == 2]  # Assuming class 2 is 'car'\n",
        "\n",
        "# # Plot original image with bounding boxes\n",
        "# fig, ax = plt.subplots(figsize=(12, 8))\n",
        "# ax.imshow(test_image)\n",
        "# ax.axis('off')  # Hide the axes\n",
        "\n",
        "# # Iterate over detected cars\n",
        "# for box in car_detections.xyxy.cpu().numpy():\n",
        "#     x1, y1, x2, y2 = box.astype(int)\n",
        "#     # Crop the car image\n",
        "#     car_image = test_image[y1:y2, x1:x2]\n",
        "#     car_image = cv2.resize(car_image, (224, 224))\n",
        "#     car_image_array = img_to_array(car_image)\n",
        "#     car_image_array = np.expand_dims(car_image_array, axis=0)\n",
        "\n",
        "#     # Predict the viewpoint\n",
        "#     prediction = viewpoint_model.predict(car_image_array)\n",
        "#     predicted_class = np.argmax(prediction)\n",
        "#     predicted_angle = class_to_angle[predicted_class]\n",
        "#     print(predicted_angle)\n",
        "\n",
        "#     # Draw bounding box and viewpoint arrow\n",
        "#     rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='red', facecolor='none')\n",
        "#     ax.add_patch(rect)\n",
        "#     plot_arrow(predicted_angle, (x1, y1, x2, y2), ax)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "for image_name in os.listdir(folder_path):\n",
        "    # Check if file is an image\n",
        "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "        test_image_path = os.path.join(folder_path, image_name)\n",
        "        test_image = cv2.imread(test_image_path)\n",
        "        test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform car detection\n",
        "        yolov8_results = yolov8_model(test_image)\n",
        "        car_detections = yolov8_results[0].boxes[yolov8_results[0].boxes.cls == 2]  # Assuming class 2 is 'car'\n",
        "\n",
        "        # Plot original image with bounding boxes\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        ax.imshow(test_image)\n",
        "        ax.axis('off')  # Hide the axes\n",
        "\n",
        "        # Iterate over detected cars\n",
        "        for box in car_detections.xyxy.cpu().numpy():\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "            # Crop the car image\n",
        "            car_image = test_image[y1:y2, x1:x2]\n",
        "            car_image = cv2.resize(car_image, (224, 224))\n",
        "            car_image_array = img_to_array(car_image)\n",
        "            car_image_array = np.expand_dims(car_image_array, axis=0)\n",
        "\n",
        "            # Predict the viewpoint\n",
        "            prediction = viewpoint_model.predict(car_image_array)\n",
        "            predicted_class = np.argmax(prediction)\n",
        "            predicted_angle = class_to_angle[predicted_class]\n",
        "\n",
        "            # Draw bounding box and viewpoint arrow\n",
        "            rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='red', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            plot_arrow(predicted_angle, (x1, y1, x2, y2), ax)\n",
        "\n",
        "        plt.show()\n",
        "        # Save the figure\n",
        "        output_image_name = os.path.splitext(image_name)[0] + '.png'  # Save as PNG\n",
        "        output_image_path = os.path.join(output_folder_path, output_image_name)\n",
        "\n",
        "        plt.savefig(output_image_path, bbox_inches='tight')\n",
        "        plt.close(fig)  # Close the figure to free up memory\n"
      ],
      "metadata": {
        "id": "FTqfR53xMfiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}